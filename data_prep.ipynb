{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#General libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "#Libraries for feature engineering\n",
    "from astral.sun import sun\n",
    "from astral import LocationInfo\n",
    "from workalendar.europe import Germany\n",
    "from scipy.stats import entropy, zscore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "def is_daytime(timestamp):\n",
    "    s = sun(location.observer, date=timestamp.date())\n",
    "    return s['sunrise'].time() < timestamp.time() < s['sunset'].time()\n",
    "\n",
    "def is_holiday(timestamp):\n",
    "    return cal.is_working_day(timestamp)\n",
    "\n",
    "def get_season(timestamp):\n",
    "    if (timestamp.month > 11 or timestamp.month < 3):\n",
    "        return 'WINTER'\n",
    "    elif (timestamp.month == 3 or timestamp.month <=5):\n",
    "        return 'SPRING'\n",
    "    elif (timestamp.month >=6 and timestamp.month <=9):\n",
    "        return 'SUMMER'\n",
    "    else:\n",
    "        return 'FALL'\n",
    "\n",
    "def calendar_features(df, quarter_hour=True, hour=True, weekday=True, month=True, quarter=True):\n",
    "    features = df.copy()\n",
    "    columns = []\n",
    "    if quarter_hour:\n",
    "        features['QUARTERHOUR'] = features.timestamp.dt.minute\n",
    "        columns.append('QUARTERHOUR')\n",
    "    if hour:\n",
    "        features['HOUR'] = features.timestamp.dt.hour\n",
    "        columns.append('HOUR')\n",
    "    if weekday:\n",
    "        features['WEEKDAY'] = features.timestamp.dt.dayofweek\n",
    "        columns.append('WEEKDAY')\n",
    "    if month:\n",
    "        features['MONTH'] = features.timestamp.dt.month\n",
    "        columns.append('MONTH')\n",
    "    if quarter:\n",
    "        features['QUARTER'] = features.timestamp.dt.quarter\n",
    "        columns.append('QUARTER')\n",
    "\n",
    "    dummies = pd.get_dummies(features[columns], columns=columns)\n",
    "\n",
    "    return dummies\n",
    "\n",
    "def window_metrics_15m(df, target, lag=True, ma=True, maxi=True, mini=True, suma=True, diff=True, entropy=False, zscore=False,\n",
    "                       cos=False, freq=[32, 96, 672]):\n",
    "\n",
    "    features = df.copy()\n",
    "\n",
    "\n",
    "    for i in range(1,25):\n",
    "\n",
    "        if i < 4:\n",
    "\n",
    "            if lag:\n",
    "                features['LAG_'+str((i)*15)+'MIN'] = features[target].shift((i))\n",
    "                features['LAG_'+str(i)+'H'] = features[target].shift((i)*4)\n",
    "                features['LAG_'+str(i)+'D'] = features[target].shift((i)*96)\n",
    "            if ma:\n",
    "                features['MA_'+str((i+1)*15)+'MIN'] = features[target].rolling((i+1), closed='left').mean()\n",
    "                features['MA_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').mean()\n",
    "                features['MA_'+str(i)+'D'] = features[target].rolling((i)*96, closed='left').mean()\n",
    "            if maxi:\n",
    "                features['MAX_'+str((i+1)*15)+'MIN'] = features[target].rolling((i+1), closed='left').max()\n",
    "                features['MAX_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').max()\n",
    "                features['MAX_'+str(i)+'D'] = features[target].rolling((i)*96, closed='left').max()\n",
    "            if mini:\n",
    "                features['MIN_'+str((i+1)*15)+'MIN'] = features[target].rolling((i+1), closed='left').min()\n",
    "                features['MIN_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').min()\n",
    "                features['MIN_'+str(i)+'D'] = features[target].rolling((i)*96, closed='left').min()\n",
    "            if suma:\n",
    "                features['SUM_'+str((i+1)*15)+'MIN'] = features[target].rolling((i+1), closed='left').sum()\n",
    "                features['SUM_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').sum()\n",
    "                features['SUM_'+str(i)+'D'] = features[target].rolling((i)*96, closed='left').sum()\n",
    "            if diff:\n",
    "                features['DIFF_96_'+str((i)*15)+'MIN'] = features[target].shift((i)).diff(96)\n",
    "                features['DIFF_96_'+str(i)+'H'] = features[target].shift((i)*4).diff(96)\n",
    "                features['DIFF_96_'+str(i)+'D'] = features[target].shift((i)*96).diff(96)\n",
    "                features['DIFF_672_'+str((i)*15)+'MIN'] = features[target].shift((i)).diff(672)\n",
    "                features['DIFF_672_'+str(i)+'H'] = features[target].shift((i)*4).diff(672)\n",
    "                features['DIFF_672_'+str(i)+'D'] = features[target].shift((i)*96).diff(672)\n",
    "                features['DIFF_96_672_'+str((i)*15)+'MIN'] = features[target].shift((i)).diff(96).diff(672)\n",
    "                features['DIFF_96_672_'+str(i)+'H'] = features[target].shift((i)*4).diff(96).diff(672)\n",
    "                features['DIFF_96_672_'+str(i)+'D'] = features[target].shift((i)*96).diff(96).diff(672)\n",
    "            if entropy:\n",
    "                features['ENTROPY_'+str((i+1)*15)+'MIN'] = features[target].rolling((i+1), closed='left').apply(lambda x: entropy(np.histogram(x, bins='fd')[0]), raw=True)\n",
    "                features['ENTROPY_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').apply(lambda x: entropy(np.histogram(x, bins='fd')[0]), raw=True)\n",
    "                features['ENTROPY_'+str(i)+'D'] = features[target].rolling((i)*96, closed='left').apply(lambda x: entropy(np.histogram(x, bins='fd')[0]), raw=True)\n",
    "            if zscore:\n",
    "                features['ZSCORE_'+str((i+1)*15)+'MIN'] = features[target].rolling((i+1), closed='left').apply(lambda x: zscore(x)[-1], raw=True)\n",
    "                features['ZSCORE_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').apply(lambda x: zscore(x)[-1], raw=True)\n",
    "                features['ZSCORE_'+str(i)+'D'] = features[target].rolling((i)*96, closed='left').apply(lambda x: zscore(x)[-1], raw=True)\n",
    "            if cos:\n",
    "                for k in freq:\n",
    "                    features['COS_'+str(k)+'_LAG_'+str((i)*15)+'MIN'] = np.cos(features[target].shift((i))/k)\n",
    "                    features['COS_'+str(k)+'_LAG_'+str(i)+'H'] = np.cos(features[target].shift((i)*4)/k)\n",
    "                    features['COS_'+str(k)+'_LAG_'+str(i)+'D'] = np.cos(features[target].shift((i)*96)/k)\n",
    "\n",
    "        elif i > 7:\n",
    "\n",
    "            if lag:\n",
    "                features['LAG_'+str(i)+'H'] = features[target].shift((i)*4)\n",
    "            if ma:\n",
    "                features['MA_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').mean()\n",
    "            if maxi:\n",
    "                features['MAX_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').max()\n",
    "            if mini:\n",
    "                features['MIN_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').min()\n",
    "            if suma:\n",
    "                features['SUM_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').sum()\n",
    "            if diff:\n",
    "                features['DIFF_96_'+str(i)+'H'] = features[target].shift((i)*4).diff(96)\n",
    "                features['DIFF_672_'+str(i)+'H'] = features[target].shift((i)*4).diff(672)\n",
    "                features['DIFF_96_672_'+str(i)+'H'] = features[target].shift((i)*4).diff(96).diff(672)\n",
    "            if entropy:\n",
    "                features['ENTROPY_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').apply(lambda x: entropy(np.histogram(x, bins='fd')[0]), raw=True)\n",
    "            if zscore:\n",
    "                features['ZSCORE_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').apply(lambda x: zscore(x)[-1], raw=True)\n",
    "            if cos:\n",
    "                for k in freq:\n",
    "                    features['COS_'+str(k)+'_LAG_'+str(i)+'H'] = np.cos(features[target].shift((i)*4)/k)\n",
    "\n",
    "        else:\n",
    "            if lag:\n",
    "                features['LAG_'+str(i)+'H'] = features[target].shift((i)*4)\n",
    "                features['LAG_'+str(i)+'D'] = features[target].shift((i)*96)\n",
    "            if ma:\n",
    "                features['MA_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').mean()\n",
    "                features['MA_'+str(i)+'D'] = features[target].rolling((i)*96, closed='left').mean()\n",
    "            if maxi:\n",
    "                features['MAX_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').max()\n",
    "                features['MAX_'+str(i)+'D'] = features[target].rolling((i)*96, closed='left').max()\n",
    "            if mini:\n",
    "                features['MIN_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').min()\n",
    "                features['MIN_'+str(i)+'D'] = features[target].rolling((i)*96, closed='left').min()\n",
    "            if suma:\n",
    "                features['SUM_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').sum()\n",
    "                features['SUM_'+str(i)+'D'] = features[target].rolling((i)*96, closed='left').sum()\n",
    "            if diff:\n",
    "                features['DIFF_96_'+str(i)+'H'] = features[target].shift((i)*4).diff(96)\n",
    "                features['DIFF_96_'+str(i)+'D'] = features[target].shift((i)*96).diff(96)\n",
    "                features['DIFF_672_'+str(i)+'H'] = features[target].shift((i)*4).diff(672)\n",
    "                features['DIFF_672_'+str(i)+'D'] = features[target].shift((i)*96).diff(672)\n",
    "                features['DIFF_96_672_'+str(i)+'H'] = features[target].shift((i)*4).diff(96).diff(672)\n",
    "                features['DIFF_96_672_'+str(i)+'D'] = features[target].shift((i)*96).diff(96).diff(672)\n",
    "            if entropy:\n",
    "                features['ENTROPY_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').apply(lambda x: entropy(np.histogram(x, bins='fd')[0]), raw=True)\n",
    "                features['ENTROPY_'+str(i)+'D'] = features[target].rolling((i)*96, closed='left').apply(lambda x: entropy(np.histogram(x, bins='fd')[0]), raw=True)\n",
    "            if zscore:\n",
    "                features['ZSCORE_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').apply(lambda x: zscore(x)[-1], raw=True)\n",
    "                features['ZSCORE_'+str(i)+'D'] = features[target].rolling((i)*96, closed='left').apply(lambda x: zscore(x)[-1], raw=True)\n",
    "            if cos:\n",
    "                for k in freq:\n",
    "                    features['COS_'+str(k)+'_LAG_'+str(i)+'H'] = np.cos(features[target].shift((i)*4)/k)\n",
    "                    features['COS_'+str(k)+'_LAG_'+str(i)+'D'] = np.cos(features[target].shift((i)*96)/k)\n",
    "    return features.drop(columns=[target])\n",
    "\n",
    "\n",
    "def window_metrics_15m_SM(df, target, lag=True, ma=True, maxi=True, mini=True, suma=True, diff=True, entropy=False, zscore=False, end=25):\n",
    "\n",
    "    features = df.copy()\n",
    "\n",
    "\n",
    "    for i in range(1, end):\n",
    "\n",
    "        if lag:\n",
    "            features['LAG_'+str((i)*15)+'MIN'] = features[target].shift((i))\n",
    "            features['LAG_'+str(i)+'H'] = features[target].shift((i)*4)\n",
    "            if i == 7:\n",
    "                features['LAG_'+str(i)+'D'] = features[target].shift((i)*96)\n",
    "        if ma:\n",
    "            features['MA_'+str((i+1)*15)+'MIN'] = features[target].rolling((i+1), closed='left').mean()\n",
    "            features['MA_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').mean()\n",
    "            if i == 7:\n",
    "                features['MA_'+str(i)+'D'] = features[target].rolling((i)*96, closed='left').mean()\n",
    "        if maxi:\n",
    "            features['MAX_'+str((i+1)*15)+'MIN'] = features[target].rolling((i+1), closed='left').max()\n",
    "            features['MAX_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').max()\n",
    "            if i == 7:\n",
    "                features['MAX_'+str(i)+'D'] = features[target].rolling((i)*96, closed='left').max()\n",
    "        if mini:\n",
    "            features['MIN_'+str((i+1)*15)+'MIN'] = features[target].rolling((i+1), closed='left').min()\n",
    "            features['MIN_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').min()\n",
    "            if i == 7:\n",
    "                features['MIN_'+str(i)+'D'] = features[target].rolling((i)*96, closed='left').min()\n",
    "        if suma:\n",
    "            features['SUM_'+str((i+1)*15)+'MIN'] = features[target].rolling((i+1), closed='left').sum()\n",
    "            features['SUM_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').sum()\n",
    "            if i == 7:\n",
    "                features['SUM_'+str(i)+'D'] = features[target].rolling((i)*96, closed='left').sum()\n",
    "        if diff:\n",
    "            features['DIFF_96_'+str((i)*15)+'MIN'] = features[target].shift((i)).diff(96)\n",
    "            features['DIFF_96_'+str(i)+'H'] = features[target].shift((i)*4).diff(96)\n",
    "            if i == 7:\n",
    "                features['DIFF_96_'+str(i)+'D'] = features[target].shift((i)*96).diff(96)\n",
    "            features['DIFF_672_'+str((i)*15)+'MIN'] = features[target].shift((i)).diff(672)\n",
    "            features['DIFF_672_'+str(i)+'H'] = features[target].shift((i)*4).diff(672)\n",
    "            if i == 7:\n",
    "                features['DIFF_672_'+str(i)+'D'] = features[target].shift((i)*96).diff(672)\n",
    "            features['DIFF_96_672_'+str((i)*15)+'MIN'] = features[target].shift((i)).diff(96).diff(672)\n",
    "            features['DIFF_96_672_'+str(i)+'H'] = features[target].shift((i)*4).diff(96).diff(672)\n",
    "            if i == 7:\n",
    "                features['DIFF_96_672_'+str(i)+'D'] = features[target].shift((i)*96).diff(96).diff(672)\n",
    "        if entropy:\n",
    "            features['ENTROPY_'+str((i+1)*15)+'MIN'] = features[target].rolling((i+1), closed='left').apply(lambda x: entropy(np.histogram(x, bins='fd')[0]), raw=True)\n",
    "            features['ENTROPY_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').apply(lambda x: entropy(np.histogram(x, bins='fd')[0]), raw=True)\n",
    "            if i == 7:\n",
    "                features['ENTROPY_'+str(i)+'D'] = features[target].rolling((i)*96, closed='left').apply(lambda x: entropy(np.histogram(x, bins='fd')[0]), raw=True)\n",
    "        if zscore:\n",
    "            features['ZSCORE_'+str((i+1)*15)+'MIN'] = features[target].rolling((i+1), closed='left').apply(lambda x: zscore(x)[-1], raw=True)\n",
    "            features['ZSCORE_'+str(i)+'H'] = features[target].rolling((i)*4, closed='left').apply(lambda x: zscore(x)[-1], raw=True)\n",
    "            if i == 7:\n",
    "                features['ZSCORE_'+str(i)+'D'] = features[target].rolling((i)*96, closed='left').apply(lambda x: zscore(x)[-1], raw=True)\n",
    "        # if cos:\n",
    "        #     for k in freq:\n",
    "        #         features['COS_'+str(k)+'_LAG_'+str((i)*15)+'MIN'] = np.cos(features[target].shift((i))/k)\n",
    "        #         features['COS_'+str(k)+'_LAG_'+str(i)+'H'] = np.cos(features[target].shift((i)*4)/k)\n",
    "        #         if i == 7:\n",
    "        #             features['COS_'+str(k)+'_LAG_'+str(i)+'D'] = np.cos(features[target].shift((i)*96)/k)\n",
    "\n",
    "    return features.drop(columns=[target])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "df = pd.read_excel('dataset_real_003.xlsx', sheet_name=0)\n",
    "df2 = pd.read_excel('dataset_real_003.xlsx', sheet_name=1)\n",
    "data = pd.merge(df, df2, on='Date', how='outer')\n",
    "data['consumption'] = data['Consumption (kWh)_x'] + data['Consumption (kWh)_y']\n",
    "data = data[['Date', 'consumption']]\n",
    "data.columns = ['timestamp', 'consumption']\n",
    "df = data.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "data": {
      "text/plain": "                     consumption  is_daytime  holiday  SEASON_FALL  \\\ntimestamp                                                            \n2021-01-01 05:00:00       84.725           0        1            0   \n2021-01-01 05:15:00       84.725           0        1            0   \n2021-01-01 05:30:00       82.225           0        1            0   \n2021-01-01 05:45:00       84.725           0        1            0   \n2021-01-01 06:00:00       84.725           0        1            0   \n...                          ...         ...      ...          ...   \n2022-09-19 22:45:00      416.823           0        0            0   \n2022-09-19 23:00:00      409.908           0        0            0   \n2022-09-19 23:15:00      417.320           0        0            0   \n2022-09-19 23:30:00      428.716           0        0            0   \n2022-09-19 23:45:00      437.169           0        0            0   \n\n                     SEASON_SPRING  SEASON_SUMMER  SEASON_WINTER  \\\ntimestamp                                                          \n2021-01-01 05:00:00              0              0              1   \n2021-01-01 05:15:00              0              0              1   \n2021-01-01 05:30:00              0              0              1   \n2021-01-01 05:45:00              0              0              1   \n2021-01-01 06:00:00              0              0              1   \n...                            ...            ...            ...   \n2022-09-19 22:45:00              0              1              0   \n2022-09-19 23:00:00              0              1              0   \n2022-09-19 23:15:00              0              1              0   \n2022-09-19 23:30:00              0              1              0   \n2022-09-19 23:45:00              0              1              0   \n\n                     QUARTERHOUR_0  QUARTERHOUR_15  QUARTERHOUR_30  ...  \\\ntimestamp                                                           ...   \n2021-01-01 05:00:00              1               0               0  ...   \n2021-01-01 05:15:00              0               1               0  ...   \n2021-01-01 05:30:00              0               0               1  ...   \n2021-01-01 05:45:00              0               0               0  ...   \n2021-01-01 06:00:00              1               0               0  ...   \n...                            ...             ...             ...  ...   \n2022-09-19 22:45:00              0               0               0  ...   \n2022-09-19 23:00:00              1               0               0  ...   \n2022-09-19 23:15:00              0               1               0  ...   \n2022-09-19 23:30:00              0               0               1  ...   \n2022-09-19 23:45:00              0               0               0  ...   \n\n                     QUARTER_4       MA_3H   MAX_5H   MAX_3H   MIN_5H  \\\ntimestamp                                                               \n2021-01-01 05:00:00          0   81.210833   89.670   89.670   77.280   \n2021-01-01 05:15:00          0   81.210833   89.670   89.670   77.280   \n2021-01-01 05:30:00          0   81.622917   89.670   89.670   77.280   \n2021-01-01 05:45:00          0   82.035000   89.670   89.670   77.280   \n2021-01-01 06:00:00          0   82.447083   89.670   89.670   77.280   \n...                        ...         ...      ...      ...      ...   \n2022-09-19 22:45:00          0  381.675083  411.477  411.477  353.724   \n2022-09-19 23:00:00          0  386.933333  416.823  416.823  353.724   \n2022-09-19 23:15:00          0  390.328000  416.823  416.823  353.724   \n2022-09-19 23:30:00          0  392.050750  417.320  417.320  353.724   \n2022-09-19 23:45:00          0  393.835333  428.716  428.716  353.724   \n\n                      MIN_3H    SUM_5H    SUM_3H  WEEKEND  WORKDAY  \ntimestamp                                                           \n2021-01-01 05:00:00   77.280  1629.995   974.530    False        0  \n2021-01-01 05:15:00   77.280  1634.940   974.530    False        0  \n2021-01-01 05:30:00   77.280  1634.940   979.475    False        0  \n2021-01-01 05:45:00   77.280  1639.885   984.420    False        0  \n2021-01-01 06:00:00   77.280  1639.885   989.365    False        0  \n...                      ...       ...       ...      ...      ...  \n2022-09-19 22:45:00  353.724  7642.745  4580.101    False        1  \n2022-09-19 23:00:00  358.903  7656.893  4643.200    False        1  \n2022-09-19 23:15:00  358.903  7696.077  4683.936    False        1  \n2022-09-19 23:30:00  358.903  7747.176  4704.609    False        1  \n2022-09-19 23:45:00  358.903  7793.234  4726.024    False        1  \n\n[59276 rows x 67 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>consumption</th>\n      <th>is_daytime</th>\n      <th>holiday</th>\n      <th>SEASON_FALL</th>\n      <th>SEASON_SPRING</th>\n      <th>SEASON_SUMMER</th>\n      <th>SEASON_WINTER</th>\n      <th>QUARTERHOUR_0</th>\n      <th>QUARTERHOUR_15</th>\n      <th>QUARTERHOUR_30</th>\n      <th>...</th>\n      <th>QUARTER_4</th>\n      <th>MA_3H</th>\n      <th>MAX_5H</th>\n      <th>MAX_3H</th>\n      <th>MIN_5H</th>\n      <th>MIN_3H</th>\n      <th>SUM_5H</th>\n      <th>SUM_3H</th>\n      <th>WEEKEND</th>\n      <th>WORKDAY</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2021-01-01 05:00:00</th>\n      <td>84.725</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>81.210833</td>\n      <td>89.670</td>\n      <td>89.670</td>\n      <td>77.280</td>\n      <td>77.280</td>\n      <td>1629.995</td>\n      <td>974.530</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-01-01 05:15:00</th>\n      <td>84.725</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>81.210833</td>\n      <td>89.670</td>\n      <td>89.670</td>\n      <td>77.280</td>\n      <td>77.280</td>\n      <td>1634.940</td>\n      <td>974.530</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-01-01 05:30:00</th>\n      <td>82.225</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>81.622917</td>\n      <td>89.670</td>\n      <td>89.670</td>\n      <td>77.280</td>\n      <td>77.280</td>\n      <td>1634.940</td>\n      <td>979.475</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-01-01 05:45:00</th>\n      <td>84.725</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>82.035000</td>\n      <td>89.670</td>\n      <td>89.670</td>\n      <td>77.280</td>\n      <td>77.280</td>\n      <td>1639.885</td>\n      <td>984.420</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-01-01 06:00:00</th>\n      <td>84.725</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>82.447083</td>\n      <td>89.670</td>\n      <td>89.670</td>\n      <td>77.280</td>\n      <td>77.280</td>\n      <td>1639.885</td>\n      <td>989.365</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2022-09-19 22:45:00</th>\n      <td>416.823</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>381.675083</td>\n      <td>411.477</td>\n      <td>411.477</td>\n      <td>353.724</td>\n      <td>353.724</td>\n      <td>7642.745</td>\n      <td>4580.101</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2022-09-19 23:00:00</th>\n      <td>409.908</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>386.933333</td>\n      <td>416.823</td>\n      <td>416.823</td>\n      <td>353.724</td>\n      <td>358.903</td>\n      <td>7656.893</td>\n      <td>4643.200</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2022-09-19 23:15:00</th>\n      <td>417.320</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>390.328000</td>\n      <td>416.823</td>\n      <td>416.823</td>\n      <td>353.724</td>\n      <td>358.903</td>\n      <td>7696.077</td>\n      <td>4683.936</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2022-09-19 23:30:00</th>\n      <td>428.716</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>392.050750</td>\n      <td>417.320</td>\n      <td>417.320</td>\n      <td>353.724</td>\n      <td>358.903</td>\n      <td>7747.176</td>\n      <td>4704.609</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2022-09-19 23:45:00</th>\n      <td>437.169</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>393.835333</td>\n      <td>428.716</td>\n      <td>428.716</td>\n      <td>353.724</td>\n      <td>358.903</td>\n      <td>7793.234</td>\n      <td>4726.024</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>59276 rows × 67 columns</p>\n</div>"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the location of interest (e.g. New York)\n",
    "location = LocationInfo(\"Werther\", \"Germany\", \"Europe/Berlin\", 52.0794, 8.4399)\n",
    "df['is_daytime'] = df['timestamp'].apply(is_daytime).astype(int)\n",
    "\n",
    "cal = Germany()\n",
    "df['holiday'] = df['timestamp'].apply(is_holiday)\n",
    "df['holiday'] = df['holiday'].astype(int)\n",
    "df['holiday'] = abs(df['holiday'] - 1)\n",
    "\n",
    "df['SEASON'] = df['timestamp'].apply(get_season)\n",
    "df = pd.get_dummies(df, columns=['SEASON'])\n",
    "\n",
    "calendar_dummies = calendar_features(df)\n",
    "df = pd.concat([df, calendar_dummies], axis=1)\n",
    "\n",
    "df.index = df['timestamp']\n",
    "df.drop(columns='timestamp', inplace=True)\n",
    "\n",
    "# window_features = window_metrics_15m_SM(df[['consumption']], 'consumption', lag=True, ma=False, maxi=False, mini=False, suma=False, diff=False, end=4+1)\n",
    "# df = pd.concat([df, window_features], axis=1)\n",
    "\n",
    "# df[\"MA_1H\"] = df[\"consumption\"].rolling(4, closed=\"left\").mean()\n",
    "df[\"MA_3H\"] = df[\"consumption\"].rolling(12, closed=\"left\").mean()\n",
    "\n",
    "# df[\"LAG_15MIN\"] = df[\"consumption\"].shift(1)\n",
    "\n",
    "# # df[\"DIFF_15-30MIN\"] = df[\"consumption\"].shift(1).diff(1)\n",
    "# df[\"DIFFSIGN_15-30MIN\"] = np.sign(df[\"consumption\"].shift(1).diff(1))\n",
    "# # df[\"DIFF_30-45MIN\"] = df[\"consumption\"].shift(2).diff(1)\n",
    "# df[\"DIFFSIGN_30-45MIN\"] = np.sign(df[\"consumption\"].shift(2).diff(1))\n",
    "# # df[\"DIFF_45-60MIN\"] = df[\"consumption\"].shift(3).diff(1)\n",
    "# df[\"DIFFSIGN_45-60MIN\"] = np.sign(df[\"consumption\"].shift(3).diff(1))\n",
    "\n",
    "# df[\"MAX_1H\"] = df[\"consumption\"].rolling(4, closed=\"left\").max()\n",
    "df[\"MAX_5H\"] = df[\"consumption\"].rolling(20, closed=\"left\").max()\n",
    "df[\"MAX_3H\"] = df[\"consumption\"].rolling(12, closed=\"left\").max()\n",
    "# df[\"MIN_1H\"] = df[\"consumption\"].rolling(4, closed=\"left\").min()\n",
    "df[\"MIN_5H\"] = df[\"consumption\"].rolling(20, closed=\"left\").min()\n",
    "df[\"MIN_3H\"] = df[\"consumption\"].rolling(12, closed=\"left\").min()\n",
    "\n",
    "# df[\"SUM_1H\"] = df[\"consumption\"].rolling(4, closed=\"left\").sum()\n",
    "df[\"SUM_5H\"] = df[\"consumption\"].rolling(20, closed=\"left\").sum()\n",
    "df[\"SUM_3H\"] = df[\"consumption\"].rolling(12, closed=\"left\").sum()\n",
    "\n",
    "\n",
    "df['WEEKEND'] = (df.index.dayofweek >= 5)\n",
    "\n",
    "df['WORKDAY'] = 1\n",
    "df.loc[(df.WEEKEND == 1) | (df.holiday == 1), 'WORKDAY'] = 0\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "df.to_csv(\"data_prep_MA3H-MINMAX5n1-SUM35.csv\", index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
